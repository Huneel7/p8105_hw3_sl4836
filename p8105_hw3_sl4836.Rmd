---
title: "p8105_hw3_sl4836"
author: "Hun"
date: "10/16/2021"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(dplyr)
```

#ggplot theme template from Dr.Goldsmith github
```{r, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```



#Problem 0
```{r, warning=FALSE, message=FALSE}
getwd()

dir.create(file.path(getwd(), "hw3_data_file"), recursive = TRUE)

list.files()
```


#Problem 1_Data_Summary
```{r, warning=FALSE, message=FALSE}
library(p8105.datasets)
data("instacart")
```

```{r, warning=FALSE, message=FALSE}
instacart <- instacart 

instacart %>% head

instacart_names <- names(instacart)
instacart_nrow <- nrow(instacart)
instacart_ncol <- ncol(instacart)
```
The size of the dataset is **`r instacart_nrow` x**  **`r instacart_ncol`** and **`r instacart_ncol`** variables: *`r instacart_names`.* There are **`r instacart_nrow`** number of observations without missing data. Among these, there are 4 character variables and 11 numeric variables. 


#Problem 1_(a)
```{r, warning=FALSE, message=FALSE}
Arranged_aisles <- 
  instacart %>% 
  group_by(aisle) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n))

number_aisles <- 
  nrow(Arranged_aisles)

top_item <- 
  Arranged_aisles %>% 
  pull(aisle) %>%
  first()
```

There are **`r number_aisles`** aisles. **`r top_item`** are the most items ordered from aisles.

```{r}

```

#Problem 1_(b)_Making a plot that shows the number of items ordered in each aisle
```{r, warning=FALSE, message=FALSE}
Arranged_aisles %>% 
  filter(n>10000) %>%
  ggplot(aes(x = reorder(aisle, n), y = n)) + 
  geom_bar(stat = "identity") + 
  coord_flip() +
  labs(y = "Number of Items", x = "Items") +
  ggtitle("The Number of Items Ordered in Each Aisle") +
  theme(plot.title = element_text(hjust = 0.3))


```


#Problem 1_(c)_making a table showing the three most popular items in each aisles
```{r, warning=FALSE, message=FALSE}
options(knitr.kable.NA = 0)

baking_top3 <- instacart %>% 
  filter(aisle == "baking ingredients") %>% 
  group_by(product_name) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n)) %>% 
  slice(1:3) %>%
  mutate(aisle = "baking ingredients")

dog_food_top3 <- instacart %>% 
  filter(aisle == "dog food care") %>% 
  group_by(product_name) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n)) %>% 
  slice(1:3) %>%
  mutate(aisle = "dog food care")

packaged_vege_fruit_top3 <- instacart %>% 
  filter(aisle == "packaged vegetables fruits") %>% 
  group_by(product_name) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n)) %>% 
  slice(1:3) %>%
  mutate(aisle = "packaged vegetables fruits")

bind_rows(baking_top3 ,
          dog_food_top3, 
          packaged_vege_fruit_top3) %>% 
  mutate(aisle = str_to_title(aisle)) %>%
  rename(Aisle = aisle) %>%
  pivot_wider(names_from = product_name, 
              values_from = n)  %>%
  knitr::kable(align = "c", format = "pipe", 
               caption = "**Table 1: Three Most Popular Items 
               with their counts in Each Aisles**")
```

#Problem 1_(d)_Making a table showing the mean hour of the day
```{r, warning=FALSE, message=FALSE}
instacart %>% 
  filter(product_name == "Pink Lady Apples" |product_name == "Coffee Ice Cream") %>%
  group_by(product_name, order_dow) %>% 
  summarise(mean_hour = mean(order_hour_of_day)) %>%
  rename(Product_Name = product_name) %>%
  pivot_wider(names_from = order_dow, values_from = mean_hour) %>%
  knitr::kable(align = "c", format = "pipe",
               caption = "**The Mean Hour of the Day at which
               Each Item is Ordered on Each Day**"
               )
  
```

#Problem 2_Data Import
```{r, warning=FALSE, message=FALSE}
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)

data("brfss_smart2010") 
```

#Problem 2_(a)_Data_Cleaning
```{r, warning=FALSE, message=FALSE}
brfss <- brfss_smart2010 


brfss_clean <- brfss %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>%
  filter(response %in% c("Excellent", "Very good",
                         "Good","Fair", "Poor" )) %>%
  mutate(response = as.factor(response) %>% 
           fct_relevel("Poor", "Fair", "Good", "Very good",
                       "Excellent")) 

```

#Problem 2_(b)_Showing States observed at 7 or more observations
```{r, warning=FALSE, message=FALSE}
brfss_clean %>% 
  filter(year == 2002) %>% 
  group_by(locationabbr) %>% 
  summarise(n = n_distinct(locationdesc)) %>% 
  filter(n >= 7) %>%
  arrange(n)

brfss_clean %>% 
  filter(year == 2010) %>% 
  group_by(locationabbr) %>% 
  summarise(n = n_distinct(locationdesc)) %>% 
  filter(n >= 7) %>%
  arrange(n)
```
```{r, warning=FALSE, message=FALSE}
brfss_clean %>% 
  filter(response == "Excellent") %>%
  rename(States = locationabbr) %>%
  group_by(year, States) %>%
  summarise(mean_data_value = mean(data_value, na.rm=T)) %>% 
  ggplot(aes(year, mean_data_value, color=States)) + 
  geom_point(size=0.2) + 
  geom_line(aes(group=States, alpha = 0.5)) +
  theme(legend.position = "right", legend.title =
          element_text(colour="black", size=10, face="bold"), 
        legend.key.size = unit(0.5, 'cm')) 
 

```
```{r, warning=FALSE, message=FALSE}
library(ggridges)

brfss_clean %>% 
  filter(year == 2006 | year == 2010, locationabbr == "NY") %>%
  group_by(locationdesc) %>%
  ggplot(aes(response, data_value, color = response)) +
  geom_boxplot() +
  facet_wrap(.~year) + 
  ggtitle("Distribution of data_value for responses in NY State") +
  labs(x = "Levels of Response", y = "Data_Value") +
  scale_color_discrete(name="Levels of Response:")
```
#Problem 3_Loading, Tidying, and Wrangling Data
```{r, warning=FALSE, message=FALSE}
accel <- read.csv("./hw3_data_file/accel_data.csv") 

clean_accel <- accel %>% 
  janitor::clean_names() %>% 
  pivot_longer(activity_1:activity_1440, 
               names_to = "minutes_in_a_day", values_to = "activity_count", names_prefix =  "activity_") %>%
  mutate(day = day %>% 
           fct_relevel("Sunday", "Monday", "Tuesday", "Wednesday","Thursday","Friday", "Saturday")) %>% 
  mutate(weekday_vs_weekend = ifelse(day %in% c("Monday", "Tuesday", "Wednesday", "Thursday","Friday"), "weekday","weekend")) %>% 
  mutate_if(is.double, as.integer) %>%
  mutate(minutes_in_a_day = as.integer(minutes_in_a_day))
  
```

#Problem 3_Describing the resulting dataset using in-line
```{r, warning=FALSE, message=FALSE}
accel_row <- accel %>% nrow()
accel_col <- accel %>% ncol()
accel_names <- accel %>% names()


clean_accel_row <- clean_accel %>% nrow()
clean_accel_col <- clean_accel %>% ncol()
clean_accel_names <- clean_accel %>% names()

```
Originally, the dimension of the pols_month_data was **`r accel_row` x**  **`r accel_col`** and there are **`r accel_col`** variables. This represents one person's activity data for **`r accel_row` x** days. After tidying and wrangling the data, the dimension is **`r clean_accel_row` x**  **`r clean_accel_col`** and **`r clean_accel_col`** variables: *`r clean_accel_names`.* There are **`r clean_accel_row`** number of observations,this is the total of 1440 minutes of each day's combined data (**1440x35 =** **`r clean_accel_row`**). 


#Problem 3_(b)_Creating a table that shows aggregation of a total activity for each day
```{r, warning=FALSE, message=FALSE}
clean_accel %>% 
  group_by(day) %>% 
  summarize(total = sum(activity_count)) %>% 
  rename(Day = day, Total = total) %>%
  knitr::kable(align = "c", format = "pipe", caption = "**Table 1:
               Aggregation of a Total Activity across Minutes for Each Day**")

```
According to the Table 1, it's hard to say there are apparent trends across days. However, one interesting observation is that the total activity aggregation on Saturday is far lower than any other days as one can expect people normally would like to rest on Saturday. It is also to be observed the total activity on Friday has the highest aggregation. 




#Part 3
```{r, warning=FALSE, message=FALSE}
clean_accel %>%
  group_by(day, minutes_in_a_day) %>%
  rename(Day = day) %>%
  ggplot(aes(minutes_in_a_day, activity_count, color = Day)) +
  geom_point() +
  scale_x_continuous(
    breaks = c(0, 180, 360, 540, 720, 900, 1080, 1260, 1440),
    labels = c("0hr", "3hr", "6hr", "9hr", "12hr", "15hr", "18hr", "21hr", "24hr")) + 
  labs(x = "Hours", y="Activity Count") +
  ggtitle("24-hour Activity Time Courses for Each Day with one-minute interval") + 
  theme(plot.title = element_text(size=12))

```
Between 0hr (12am) to 6hr (6am), it is to be observed that the activity count of a 63 year-old male is the lowest across days as one can expect people normally sleep during those times. Around 7hr (7am), his activity count is relatively high on some Thursdays. Around 9hr (9am), his activity count is quite high on some Fridays. Around 12hr (12pm), his activity count is high on many Sundays. Between 16hr (4pm) and 17hr (5pm), his activity count is relatively high on a decent number of weekends. Between 20hr (8pm) and 22hr(10pm), his activity count is high across many days, especially on Friday followed by Saturday, Wednesday, Monday. 





