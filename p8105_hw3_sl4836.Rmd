---
title: "p8105_hw3_sl4836"
author: "Hun"
date: "10/16/2021"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(dplyr)
```

#ggplot theme template from Dr.Goldsmith github
```{r, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```



#Problem 0
```{r, warning=FALSE, message=FALSE}
getwd()

dir.create(file.path(getwd(), "hw3_data_file"), recursive = TRUE)

list.files()
```


#Problem 1_Data_Summary
```{r, warning=FALSE, message=FALSE}
library(p8105.datasets)
data("instacart")
```

```{r, warning=FALSE, message=FALSE}
instacart <- instacart 

instacart %>% head

instacart_names <- names(instacart)
instacart_nrow <- nrow(instacart)
instacart_ncol <- ncol(instacart)
```
The size of the dataset is **`r instacart_nrow` x**  **`r instacart_ncol`** and **`r instacart_ncol`** variables: *`r instacart_names`.* There are **`r instacart_nrow`** number of observations without missing data. Among these, there are 4 character variables and 11 numeric variables. 


#Problem 1_(a)
```{r, warning=FALSE, message=FALSE}
Arranged_aisles <- 
  instacart %>% 
  group_by(aisle) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n))

number_aisles <- 
  nrow(Arranged_aisles)

top_item <- 
  Arranged_aisles %>% 
  pull(aisle) %>%
  first()
```

There are **`r number_aisles`** aisles. **`r top_item`** are the most items ordered from aisles.

```{r}

```

#Problem 1_(b)_Making a plot that shows the number of items ordered in each aisle
```{r, warning=FALSE, message=FALSE}
Arranged_aisles %>% 
  filter(n>10000) %>%
  ggplot(aes(x = reorder(aisle, n), y = n)) + 
  geom_bar(stat = "identity") + 
  coord_flip() +
  labs(y = "Number of Items", x = "Items") +
  ggtitle("The Number of Items Ordered in Each Aisle") +
  theme(plot.title = element_text(hjust = 0.3))


```


#Problem 1_(c)_making a table showing the three most popular items in each aisles
```{r, warning=FALSE, message=FALSE}
options(knitr.kable.NA = 0)

baking_top3 <- instacart %>% 
  filter(aisle == "baking ingredients") %>% 
  group_by(product_name) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n)) %>% 
  slice(1:3) %>%
  mutate(aisle = "baking ingredients")

dog_food_top3 <- instacart %>% 
  filter(aisle == "dog food care") %>% 
  group_by(product_name) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n)) %>% 
  slice(1:3) %>%
  mutate(aisle = "dog food care")

packaged_vege_fruit_top3 <- instacart %>% 
  filter(aisle == "packaged vegetables fruits") %>% 
  group_by(product_name) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n)) %>% 
  slice(1:3) %>%
  mutate(aisle = "packaged vegetables fruits")

bind_rows(baking_top3 ,
          dog_food_top3, 
          packaged_vege_fruit_top3) %>% 
  mutate(aisle = str_to_title(aisle)) %>%
  rename(Aisle = aisle) %>%
  pivot_wider(names_from = product_name, 
              values_from = n)  %>%
  knitr::kable(align = "c", format = "pipe", 
               caption = "**Table 1: Three Most Popular Items 
               with their counts in Each Aisles**")
```

#Problem 1_(d)_Making a table showing the mean hour of the day
```{r, warning=FALSE, message=FALSE}
instacart %>% 
  filter(product_name == "Pink Lady Apples" |product_name == "Coffee Ice Cream") %>%
  group_by(product_name, order_dow) %>% 
  summarise(mean_hour = mean(order_hour_of_day)) %>%
  rename(Product_Name = product_name) %>%
  pivot_wider(names_from = order_dow, values_from = mean_hour) %>%
  knitr::kable(align = "c", format = "pipe",
               caption = "**The Mean Hour of the Day at which
               Each Item is Ordered on Each Day**"
               )
  
```

#Problem 2_Data Import
```{r, warning=FALSE, message=FALSE}
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)

data("brfss_smart2010") 
```

#Problem 2_(a)_Data_Cleaning
```{r, warning=FALSE, message=FALSE}
brfss <- brfss_smart2010 


brfss_clean <- brfss %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>%
  filter(response %in% c("Excellent", "Very good",
                         "Good","Fair", "Poor" )) %>%
  mutate(response = as.factor(response) %>% 
           fct_relevel("Poor", "Fair", "Good", "Very good",
                       "Excellent")) 

```

#Problem 2_(b)_Showing States observed at 7 or more observations
```{r, warning=FALSE, message=FALSE}
brfss_clean %>% 
  filter(year == 2002) %>% 
  group_by(locationabbr) %>% 
  summarise(n = n_distinct(locationdesc)) %>% 
  filter(n >= 7) %>%
  arrange(n)

brfss_clean %>% 
  filter(year == 2010) %>% 
  group_by(locationabbr) %>% 
  summarise(n = n_distinct(locationdesc)) %>% 
  filter(n >= 7) %>%
  arrange(n)
```
```{r, warning=FALSE, message=FALSE}
brfss_clean %>% 
  filter(response == "Excellent") %>%
  rename(States = locationabbr) %>%
  group_by(year, States) %>%
  summarise(mean_data_value = mean(data_value, na.rm=T)) %>%
  ggplot(aes(year, mean_data_value, color=States)) + 
  geom_point(size=0.2) + 
  geom_line(aes(group=States, alpha = 0.5)) +
  theme(legend.position = "right", legend.title =
          element_text(colour="black", size=10, face="bold")) 
 

```
```{r, warning=FALSE, message=FALSE}
library(ggridges)

brfss_clean %>% 
  filter(year == 2006 | year == 2010, locationabbr == "NY") %>%
  group_by(locationdesc) %>%
  ggplot(aes(response, data_value, color = response)) +
  geom_boxplot() +
  facet_wrap(.~year) + 
  ggtitle("Distribution of data_value for responses in NY State") +
  labs(x = "Levels of Response") +
  scale_color_discrete(name="Levels of Response")
```
#Problem 3_Loading, Tidying, and Wrangling Data
```{r, warning=FALSE, message=FALSE}
accel <- read.csv("~/Downloads/accel_data.csv") 

clean_accel <- accel %>% 
  janitor::clean_names() %>% 
  pivot_longer(activity_1:activity_1440, 
               names_to = "minutes_in_a_day", values_to = "activity_count", names_prefix =  "activity_") %>%
  mutate(day = day %>% 
           fct_relevel("Sunday", "Monday", "Tuesday", "Wednesday","Thursday","Friday", "Saturday")) %>% 
  mutate(weekday_vs_weekend = ifelse(day %in% c("Monday", "Tuesday", "Wednesday", "Thursday","Friday"), "weekday","weekend")) %>% 
  mutate_if(is.double, as.integer) %>%
  mutate(minutes_in_a_day = as.integer(minutes_in_a_day))
  
```

#Problem 3_Describing the resulting dataset using in-line
```{r, warning=FALSE, message=FALSE}
accel_row <- accel %>% nrow()
accel_col <- accel %>% ncol()
accel_names <- accel %>% names()


clean_accel_row <- clean_accel %>% nrow()
clean_accel_col <- clean_accel %>% ncol()
clean_accel_names <- clean_accel %>% names()

```
Originally, the dimension of the pols_month_data was **`r accel_row` x**  **`r accel_col`** and there are **`r accel_col`** variables. This represents one person's activity data for **`r accel_row` x** days. After tidying and wrangling the data, the dimension is **`r clean_accel_row` x**  **`r clean_accel_col`** and **`r clean_accel_col`** variables: *`r clean_accel_names`.* There are **`r clean_accel_row`** number of observations,this is the total of 1440 minutes of each day's combined data (**1440x35 =** **`r clean_accel_row`**). 


#Problem 3_(b)_Creating a table that shows aggregation of a total activity for each day
```{r, warning=FALSE, message=FALSE}
clean_accel %>% 
  group_by(day) %>% 
  summarize(total = sum(activity_count)) %>% 
  rename(Day = day, Total = total) %>%
  knitr::kable(align = "c", format = "pipe", caption = "Table 1:
               Aggregation of a Total Activity across minutes for each day")

```

#Part 3
```{r, warning=FALSE, message=FALSE}
clean_accel %>%
  group_by(day, minutes_in_a_day) %>%
  ggplot(aes(minutes_in_a_day, activity_count, color = day)) +
  geom_point() +
  scale_x_continuous(
    breaks = c(0, 180, 360, 540, 720, 900, 1080, 1260, 1440),
    labels = c("0hr", "3hr", "6hr", "9hr", "12hr", "15hr", "18hr", "21hr", "24hr")
  )

```





